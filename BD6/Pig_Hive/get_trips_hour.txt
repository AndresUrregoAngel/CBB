##################################################################################################
########## Pig script ############################################################################
##################################################################################################


## Get the qty of departures from station by hour

  ## get into the console 
  pig -x tez -useHCatalog
  ## load historical usage files per month
  trips = LOAD '/user/ingenieroandresangel/datasets/bixitrips/' USING PigStorage(',')
  AS (departure_date:chararray,departure_station:chararray,arrival_date:chararray,arrival_station:chararray,duration:long,member:int);
  
  trips_cl = FILTER trips BY $0 != 'start_date';
  
  ## Get independent relations by departure and arrival
  trips_dp = FOREACH trips_cl GENERATE $1,GetDay(ToDate($0)) as (day:int),GetHour(ToDate($0)) as (hour:int);
  trips_ar = FOREACH trips_cl GENERATE $3,GetDay(ToDate($2)) as (day:int),GetHour(ToDate($2)) as (hour:int);
  
  trips_gr_dp  = GROUP trips_dp BY (departure_station,day,hour);
  trips_gr_ar  = GROUP trips_ar BY (arrival_station,day,hour);
  
  ## Get the avg of departure and arrival
  trips_dp_qty = FOREACH trips_gr_dp {
              qty_trips = COUNT(trips_dp);
              GENERATE FLATTEN(group) as (departure_station,day,hour), qty_trips as (qty_dp_trip:int);
              };
              
  trips_ar_qty = FOREACH trips_gr_ar {
              qty_trips = COUNT(trips_ar);
              GENERATE FLATTEN(group) as (arrival_station,day,hour), qty_trips as (qty_ar_trip:int);
              }; 
  
  trips_total_ardp = JOIN trips_dp_qty by (departure_station,day,hour) , trips_ar_qty by (arrival_station,day,hour);
  
  trips_ardp = FOREACH  trips_total_ardp GENERATE (chararray) trips_dp_qty::departure_station as (stationid:chararray), (int) trips_dp_qty::day as (day:int), (int)  trips_dp_qty::hour as (hour:int), (int) trips_dp_qty::qty_dp_trip as (qty_dp_trips:int), (int) trips_ar_qty::qty_ar_trip as (qty_ar_trips:int);

 ## Store the final pig output 
 
 STORE trips_ardp INTO '/user/ingenieroandresangel/datasets/bixioutputs/tripsardp/' USING PigStorage (',');
                                                   
  
##################################################################################################
########## Hive script ###########################################################################
##################################################################################################
  
## Load the qty trips per hour / qty departures and arrivals by station per hour

CREATE EXTERNAL TABLE bixi_trips_ardp
(stationid int, day int, hour int, qty_dp_trips int, qty_ar_trips int)
COMMENT 'qty departures and arrivals by station per hour'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION '/user/ingenieroandresangel/datasets/bixioutputs/tripsardp/';


#this command will improve the query performance, tez is a nice feature to avoid go thru map reduce as query engine and the reducer CPU
set hive.execution.engine=tez; 
et hive.vectorized.execution.enabled = true;

#Load historical files coming from the json files
CREATE EXTERNAL TABLE bixi_his
(
STATIONS ARRAY<STRUCT<id: INT,s:STRING,n:string,st:string,b:string,su:string,m:string,lu:string,lc:string,bk:string,bl:string,la:float,lo:float,da:int,dx:int,ba:int,bx:int>>,
SCHEMESUSPENDED STRING,
TIMELOAD BIGINT
)
ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
LOCATION '/user/ingenieroandresangel/datasets/bixi2017/';

#checking if the load was completed successfully.
SELECT 
  temp.id,
  temp.s,
  temp.n,
  temp.st,
  temp.b,
  temp.su,
  temp.m,
  temp.lu,
  from_unixtime(CAST(CAST(temp.lu as bigint)/1000 as BIGINT), 'yyyy-MM-dd HH:mm'),
  temp.lc,
  temp.bk,
  temp.bl,
  temp.la,
  temp.lo,
  temp.da,
  temp.dx,
  temp.ba,
  temp.bx,
  schemesuspended,
  timeload
FROM
  bixi_his
  LATERAL VIEW explode(stations) exploded_table as temp;
  LIMIT 2;
  
  
  #Create the table to store the historical data
  
  CREATE TABLE bixi_status_station
  COMMENT 'This table will store only the required fields for the analysis'
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY ','
  LINES TERMINATED BY '\n'
  STORED AS TEXTFILE
  AS 
  SELECT 
  temp.s,
  temp.n,
  CAST(from_unixtime(CAST(CAST(temp.lu as bigint)/1000 as BIGINT), 'dd') AS int) as day_status, 
  CAST(from_unixtime(CAST(CAST(temp.lu as bigint)/1000 as BIGINT), 'HH') AS int) as hour_status, 
  temp.da,
  temp.dx,
  temp.ba,
  temp.bx
FROM
  bixi_his
  LATERAL VIEW explode(stations) exploded_table as temp;
  
# Get AVG damages, qty trips per hour by station top 10
  SELECT 
    sta.s as station_name,
    sta.n as station_id,
    sta.hour_status,
    CAST(AVG(sta.dx)as decimal (10,2)) as places_broken,
    CAST(AVG(sta.bx)as decimal (10,2)) as bikes_broken,
    CAST(AVG(tr.qty_dp_trips)as decimal (10,2)) as trips_dp,
    CAST(AVG(tr.qty_ar_trips)as decimal (10,2)) as trips_ar
  FROM
    bixi_status_station sta
  INNER JOIN bixi_trips_ardp tr
    ON sta.n = tr.stationid
    AND sta.day_status = tr.day
    AND sta.hour_status = tr.hour
  GROUP BY sta.s,sta.n,sta.hour_status
  ORDER BY trips_dp,trips_ar DESC
  LIMIT 100;
