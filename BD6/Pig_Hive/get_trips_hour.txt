##################################################################################################
########## Pig script ############################################################################
##################################################################################################


## Get the qty of departures from station by hour

  ## get into the console 
  pig -x tez -useHCatalog
  ## load historical usage files per month
  trips = LOAD '/user/ingenieroandresangel/datasets/bixitrips/' USING PigStorage(',')
  AS (departure_date:chararray,departure_station:chararray,arrival_date:chararray,arrival_station:chararray,duration:long,member:int);
  
  ## Get independent relations by departure and arrival
  trips_dp = FOREACH trips GENERATE $1,GetDay(ToDate($0)) as (day:int),GetHour(ToDate($0)) as (hour:int);
  trips_ar = FOREACH trips GENERATE $3,GetHour(ToDate($2)) as (hour:int);
  
  trips_gr_dp  = GROUP trips_dp BY (departure_station,day,hour);
  trips_gr_ar  = GROUP trips_ar BY (arrival_station,day,hour);
  
  ## Get the avg of departure 
  trips_dp_qty = FOREACH trips_gr_dp {
              qty_trips = COUNT(trips_dp);
              GENERATE FLATTEN(group) as (departure_station,day,hour), qty_trips as (qty_dp_trip:int);
              };
  
  STORE trips_dp_qty INTO '/user/ingenieroandresangel/datasets/bixioutputs/tripsdp/' USING PigStorage (',');
  
  trips_dp = LOAD '/user/ingenieroandresangel/datasets/bixioutputs/tripsdp/' USING PigStorage (',');
  trips_dp_qty_gr = GROUP trips_dp by ($0,$2);
  trips_dp_myn = FOREACH trips_dp_qty_gr GENERATE FLATTEN(group) as (departure_station,hour), (double) ROUND_TO(AVG(trips_dp.$3),2) as (myn_dp:double);
  
  ## Get the avg for arrival
  
  trips_ar_myn = FOREACH trips_gr_ar GENERATE FLATTEN(group) as (arrival_station,hour), AVG(trips_ar) as (myn_ar_trip:int);
  
  trips_myn = JOIN trips_dp_myn by departure_station, trips_ar_myn by arrival_station;
  
  STORE trips_counting INTO '/user/ingenieroandresangel/datasets/bixioutputs/tripshour/' USING PigStorage (',');
  
  
##################################################################################################
########## Hive script ###########################################################################
##################################################################################################
  
## Load the qty trips per hour

CREATE EXTERNAL TABLE trips_hour
( departure_station string, trip_hour int, qty_trips int)
COMMENT 'Load qty trips per station by hour'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION '/user/ingenieroandresangel/datasets/bixioutputs/tripshour/';

#this command will improve the query performance, tez is a nice feature to avoid go thru map reduce as query engine
set hive.execution.engine=tez; 

#Load historical files coming from the json files
CREATE EXTERNAL TABLE bixi_his
(
STATIONS ARRAY<STRUCT<id: INT,s:STRING,n:string,st:string,b:string,su:string,m:string,lu:string,lc:string,bk:string,bl:string,la:float,lo:float,da:int,dx:int,ba:int,bx:int>>,
SCHEMESUSPENDED STRING,
TIMELOAD BIGINT
)
ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
LOCATION '/user/ingenieroandresangel/datasets/bixi2017/';

#checking if the load was completed successfully.
SELECT 
  temp.id,
  temp.s,
  temp.n,
  temp.st,
  temp.b,
  temp.su,
  temp.m,
  temp.lu,
  from_unixtime(CAST(CAST(temp.lu as bigint)/1000 as BIGINT), 'yyyy-MM-dd HH:mm'),
  temp.lc,
  temp.bk,
  temp.bl,
  temp.la,
  temp.lo,
  temp.da,
  temp.dx,
  temp.ba,
  temp.bx,
  schemesuspended,
  timeload
FROM
  bixi_his
  LATERAL VIEW explode(stations) exploded_table as temp;
  LIMIT 2;
  
  
  #Create the table to store the historical data
  
  CREATE TABLE bixi_status_station
  COMMENT 'This table will store only the required fields for the analysis'
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY ','
  LINES TERMINATED BY '\n'
  STORED AS TEXTFILE
  AS 
  SELECT 
  temp.s,
  temp.n,
  from_unixtime(CAST(CAST(temp.lu as bigint)/1000 as BIGINT), 'yyyy-MM-dd HH:mm') as bixi_date,
  CAST(from_unixtime(CAST(CAST(temp.lu as bigint)/1000 as BIGINT), 'HH') AS int) as hour_status, 
  temp.da,
  temp.dx,
  temp.ba,
  temp.bx
FROM
  bixi_his
  LATERAL VIEW explode(stations) exploded_table as temp;
  
# Get AVG damages, qty trips per hour by station top 10
  SELECT 
    sta.s as station_name,
    sta.n as station_id,
    sta.hour_status,
    CAST(AVG(sta.dx)as decimal (10,2)) as places_broken,
    CAST(AVG(sta.bx)as decimal (10,2)) as bikes_broken,
    tr.qty_trips 
  FROM
    bixi_status_station sta
  INNER JOIN trips_hour tr
    ON sta.n = tr.departure_station
    AND sta.hour_status = tr.trip_hour
  GROUP BY sta.s,sta.n,sta.hour_status,tr.qty_trips
  ORDER BY tr.qty_trips DESC
  LIMIT 100;
