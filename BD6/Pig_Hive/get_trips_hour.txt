##################################################################################################
########## Pig script ############################################################################
##################################################################################################


## Get the qty of departures from station by hour

  ## get into the console 
  
  pig -x tez -useHCatalog

  trips = LOAD '/user/ingenieroandresangel/datasets/bixitrips/' USING PigStorage(',')
  AS (departure_date:chararray,departure_station:chararray,arrival_date:chararray,arrival_station:chararray,duration:long,member:int);
  
  trips_fl = FOREACH trips GENERATE $1,GetHour(ToDate($0)) as (hour:int);
  trips_gr = GROUP trips_fl BY (departure_station,hour);
  trips_counting = FOREACH trips_gr GENERATE FLATTEN(group) as (departure_station,hour), AVG(trips_fl) as (qty:int);
  STORE trips_counting INTO '/user/ingenieroandresangel/datasets/bixioutputs/tripshour/' USING PigStorage (',');
  
  
##################################################################################################
########## Hive script ###########################################################################
##################################################################################################
  
## Load the qty trips per hour

CREATE EXTERNAL TABLE trips_hour
( departure_station string, trip_hour int, qty_trips int)
COMMENT 'Load qty trips per station by hour'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION '/user/ingenieroandresangel/datasets/bixioutputs/tripshour/';

#this command will improve the query performance, tez is a nice feature to avoid go thru map reduce as query engine
set hive.execution.engine=tez; 

#Load historical files coming from the json files
CREATE EXTERNAL TABLE bixi_his
(
STATIONS ARRAY<STRUCT<id: INT,s:STRING,n:string,st:string,b:string,su:string,m:string,lu:string,lc:string,bk:string,bl:string,la:float,lo:float,da:int,dx:int,ba:int,bx:int>>,
SCHEMESUSPENDED STRING,
TIMELOAD BIGINT
)
ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
LOCATION '/user/ingenieroandresangel/datasets/bixi2017/';

#checking if the load was completed successfully.
SELECT 
  temp.id,
  temp.s,
  temp.n,
  temp.st,
  temp.b,
  temp.su,
  temp.m,
  temp.lu,
  from_unixtime(CAST(CAST(temp.lu as bigint)/1000 as BIGINT), 'yyyy-MM-dd HH:mm'),
  temp.lc,
  temp.bk,
  temp.bl,
  temp.la,
  temp.lo,
  temp.da,
  temp.dx,
  temp.ba,
  temp.bx,
  schemesuspended,
  timeload
FROM
  bixi_his
  LATERAL VIEW explode(stations) exploded_table as temp;
  LIMIT 2;
  
  
  #Create the table to store the historical data
  
  CREATE TABLE bixi_status_station
  COMMENT 'This table will store only the required fields for the analysis'
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY ','
  LINES TERMINATED BY '\n'
  STORED AS TEXTFILE
  AS 
  SELECT 
  temp.s,
  temp.n,
  from_unixtime(CAST(CAST(temp.lu as bigint)/1000 as BIGINT), 'yyyy-MM-dd HH:mm') as bixi_date,
  CAST(from_unixtime(CAST(CAST(temp.lu as bigint)/1000 as BIGINT), 'HH') AS int) as hour_status, 
  temp.da,
  temp.dx,
  temp.ba,
  temp.bx
FROM
  bixi_his
  LATERAL VIEW explode(stations) exploded_table as temp;
  
# Get AVG damages, qty trips per hour by station top 10
  SELECT 
    sta.s as station_name,
    sta.n as station_id,
    sta.hour_status,
    CAST(AVG(sta.dx)as decimal (10,2)) as places_broken,
    CAST(AVG(sta.bx)as decimal (10,2)) as bikes_broken,
    tr.qty_trips 
  FROM
    bixi_status_station sta
  INNER JOIN trips_hour tr
    ON sta.n = tr.departure_station
    AND sta.hour_status = tr.trip_hour
  GROUP BY sta.s,sta.n,sta.hour_status,tr.qty_trips
  ORDER BY tr.qty_trips DESC
  LIMIT 100;
